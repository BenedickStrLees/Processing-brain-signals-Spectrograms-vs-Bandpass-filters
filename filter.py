# -*- coding: utf-8 -*-
"""filter.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WUiFJ8vZRrDRnVMTLWE2vx5i9muwMwy5

# Import libraries and files
"""

import librosa
import random
import librosa.display as lida
from scipy.signal import butter, lfilter
import numpy as np
import pandas as pd
import os
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.optimizers import Adadelta
from keras.utils.np_utils import to_categorical
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, AvgPool2D, BatchNormalization, Reshape
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import LearningRateScheduler
import scipy.io as spio
import torch.nn as nn
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score

data_path='/content/drive/MyDrive/Coursework_C/'

# read training data file
mat = spio.loadmat(data_path + 'training.mat', squeeze_me=True)
d = mat['d']
Index = mat['Index']
Class = mat['Class']
Index_sorted=sorted(Index)

# read submition data file
mat = spio.loadmat(data_path + 'submission.mat', squeeze_me=True)
submission = mat['d']

"""# Functions to make a spectrogram"""

def slice_into_frames(amplitudes, window_length, hop_length):
    return librosa.core.spectrum.util.frame(
        np.pad(amplitudes, int(window_length // 2), mode='reflect'),
        frame_length=window_length, hop_length=hop_length)
    # returns [window_length, num_windows]

def get_STFT(amplitudes, window_length, hop_length):
    # slicing into intersecting frames [window_length, num_frames]
    frames = slice_into_frames(amplitudes, window_length, hop_length)
    
    # getting weights for Fourier, float[window_length]
    fft_weights = librosa.core.spectrum.get_window('hann', window_length, fftbins=True)
    
    # transforming with Fourier
    stft = np.fft.rfft(frames * fft_weights[:, None], axis=0)
    return stft

#getting spectrogram
def get_spectrogram(data,index,window,hop):
  stft = get_STFT(data[index-10:index+40],window,hop)
  spectrogram = np.abs(stft ** 2)
  #return(librosa.amplitude_to_db(spectrogram, ref=np.max))
  return(spectrogram)

#normalizing "pixels"
def spec_to_image(spec, eps=1e-6):
        mean = spec.mean()
        std = spec.std()
        spec_norm = (spec - mean) / (std + eps)
        spec_min, spec_max = spec_norm.min(), spec_norm.max()
        spec_scaled = 255 * (spec_norm - spec_min) / (spec_max - spec_min)
        spec_scaled = spec_scaled.astype(np.uint8)
        return np.array(spec_scaled)

s=get_spectrogram(d,567211,37,1)
lida.specshow(s, sr=25000, x_axis='s', y_axis='hz');
plt.title('Spectrogram')
plt.show
s.shape

plt.imshow(spec_to_image(s), interpolation='none')
spec_to_image(s).shape

"""# Filter submission"""

def filter_data(data, low=15, high=8000, sf=25000, order=4):
     nyq = sf/2   # Set bands
     low = low/nyq
     high = high/nyq # Calculate coefficients
     b, a = butter(order, [low, high], btype='band')   # Filter signal
     filtered_data = lfilter(b, a, data)
     return filtered_data

submission_filtered=filter_data(submission)

plt.plot(np.array(range(submission[480000:482500].size))/25000, submission[480000:482500])
plt.title('Signal in real time')
plt.xlabel('time  (seconds)')
plt.ylabel('amplitude  (mV)')
plt.plot(np.array(range(submission_filtered[480000:482500].size))/25000, submission_filtered[480000:482500])
plt.show()

plt.title('Signal in real time')
plt.xlabel('time  (seconds)')
plt.ylabel('amplitude  (mV)')
plt.plot(np.array(range(submission.size))/25000, submission)
plt.plot(np.array(range(submission_filtered.size))/25000, submission_filtered)
plt.show()

"""# Identify peaks

Now that we separated the high frequency spike band from the noisy low frequency band we can extract the individual spikes. For this we will write a simple function that does the following:

    1. Find data points in the signal that are above a certain threshold
    2. Define a window around these events and “cut them out”
    3. Align them to their peak amplitude

Additionally we will also define an upper threshold. Data points above this threshold will be rejected as they are likely high frequency artifacts. Such artifacts may arise through movements of the patient or might reflect electrical events like switching on or off a light bulb in the room.

Arguements: 
1.   the filtered data
2.   the number of samples or window which should be extracted from the signal 
3. the threshold factor (mean(signal)*tf) 
4. an offset expressed in number of samples which shifts the maximum peak from the center 
5. the upper threshold which excludes data points above this limit to avoid extracting artifacts.
"""

def get_spikes(data, spike_window=20, tf=10, offset=0, max_thresh=15):
    # Calculate threshold based on data mean
    thresh = np.mean(np.abs(data))*tf
    # Find positions wherere the threshold is crossed
    pos = np.where(data > thresh)[0] 
    pos = pos[pos > spike_window]
    # Extract potential spikes and align them to the maximum
    spike_samp = []
    wave_form = np.empty([1, spike_window*2])
    for i in pos:
        if i < data.shape[0] - (spike_window+1):
            # Data from position where threshold is crossed to end of window
            tmp_waveform = data[i:i+spike_window*2]
            # Check if data in window is below upper threshold (artifact rejection)
            if np.max(tmp_waveform) < max_thresh:
                # Find sample with maximum data point in window
                tmp_samp = np.argmax(tmp_waveform) +i
                # Re-center window on maximum sample and shift it by offset
                tmp_waveform = data[tmp_samp-(spike_window-offset):tmp_samp+(spike_window+offset)]
                # Append data
                spike_samp = np.append(spike_samp, tmp_samp)
                wave_form = np.append(wave_form, tmp_waveform.reshape(1, spike_window*2), axis=0)
    return spike_samp, wave_form

spike_samp, wave_form = get_spikes(submission_filtered, spike_window=20, tf=5)
spike_samp=spike_samp.astype(int)
np.random.seed(42)
fig, ax = plt.subplots(figsize=(15, 5))

for i in range(20):
    spike = np.random.randint(0, wave_form.shape[0])
    ax.plot(wave_form[spike, :])

ax.set_xlim([-10, 50])
ax.set_xlabel('# sample')
ax.set_ylabel('amplitude [uV]')
ax.set_title('spike waveforms')
plt.show()
print((spike_samp).shape)
print((wave_form).shape)
print(spike_samp[222])

window=37
hop=1
row=19
column=40
spectr_to_predict=[]
# making spectrograms
for spn in spike_samp:
    spec=spec_to_image(get_spectrogram(submission_filtered,spn+10,window,hop))
    spectr_to_predict.append(spec)
spectr_to_predict=np.array(spectr_to_predict)
spectr_to_predict = spectr_to_predict.reshape(spectr_to_predict.shape[0], row, column, 1)
print(spectr_to_predict.shape)

s=get_spectrogram(submission_filtered,140,37,1)
lida.specshow(s, sr=25000, x_axis='s', y_axis='hz');
plt.title('Spectrogram')
plt.show
s.shape

"""# Prepaire training and validation data"""

#arrange Index (starts of activations) and Class in a list of tuples
number_of_activations=len(Index)
keys=[]
for j in range(number_of_activations):
  keys.append((Index[j],Class[j]-1)) # now the classes are named from 0 to 4 rather than from 1 to 5

#shuffle for randomness
random.shuffle(keys)
print(keys)

# short time fourier transform parameters
window=37
hop=1
# future shape of a spectrogram
row=19
column=50
# lists for future training
train_labels=[]
val_labels=[]
train_data=[]
val_data=[]
# spliting parameters for validation and training sets
count=-1
train_set_limit=len(keys)*0.9
val_set_limit=len(keys)
# making spectrograms
for key in keys:
  count+=1
  if val_set_limit>count>train_set_limit:
    val_labels.append(key[1])
    spec=spec_to_image(get_spectrogram(d,key[0],window,hop))
    val_data.append(spec)
  if count<train_set_limit:
    train_labels.append(key[1])
    spec=spec_to_image(get_spectrogram(d,key[0],window,hop))
    train_data.append(spec)
# number of classes
num_category = 5
train_data=np.array(train_data)
val_data=np.array(val_data)
train_data = train_data.reshape(train_data.shape[0], row, column, 1)
val_data = val_data.reshape(val_data.shape[0], row, column, 1)
# convert class vectors to binary class matrices
train_labels = keras.utils.to_categorical(train_labels, num_category)
val_labels = keras.utils.to_categorical(val_labels, num_category)

"""# Building and compiling the model

Convolution layer with kernel size : 3x3
    Convolution layer with kernel size : 3x3
    Max Pooling layer with pool size : 2x2
    Dropout layer
    Flattening layer
    2 Dense layered Neural Network at the end
"""

number_of_classes=5
input_shape=(row,column,1)
model = Sequential()
#convolutional layer with rectified linear unit activation
model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))
#32 convolution filters used each of size 3x3
#again
model.add(Conv2D(64, (3, 3), activation='relu'))
#64 convolution filters used each of size 3x3
#choose the best features via pooling
model.add(MaxPool2D(pool_size=(2, 2)))
#randomly turn neurons on and off to improve convergence
model.add(Dropout(0.25))
#flatten since too many dimensions, we only want a classification output
model.add(Flatten())
#fully connected to get all relevant data
model.add(Dense(128, activation='relu'))
#one more dropout for convergence's sake 
model.add(Dropout(0.5))
#output a softmax to squash the matrix into output probabilities
model.add(Dense(number_of_classes, activation='softmax'))

model.compile(loss=keras.losses.categorical_crossentropy,optimizer=Adadelta(),metrics=['accuracy'])

"""# Training"""

#model training
model_log = model.fit(train_data, train_labels,
          batch_size=130,
          epochs=200,
          verbose=1,
          validation_data=(val_data, val_labels))

score = model.evaluate(val_data, val_labels, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

# plotting the metrics
plt.plot(model_log.history['loss'])
plt.title('loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper right')
plt.tight_layout()

fig = plt.figure()
plt.plot(model_log.history['accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='lower right')

#Save the model
model_digit_json = model.to_json()
with open(data_path+'0_model.json', "w") as json_file:
    json_file.write(model_digit_json)
# serialize weights to HDF5
model.save_weights(data_path+'0_model.h5')
print("Saved to disk")

#loading the model
json_file = open(data_path+'0_model.json', 'r')
loaded_model_json = json_file.read()
json_file.close()
loaded_model = keras.models.model_from_json(loaded_model_json)
loaded_model.load_weights(data_path+'0_model.h5')
#compiling the model
loaded_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=Adadelta(),metrics=['accuracy'])

"""# Feeding data to the neral network"""

results=np.array(model.predict(spectr_to_predict))

results_class=[]
for r in results:
  results_class.append(np.argmax(r)+1)
print(results_class)